-- ============================================
-- Cortex - AI Memory System Database Schema
-- ============================================
-- Free and open-source semantic search over any codebase
--
-- Architecture:
--   - PostgreSQL 16 with pgvector extension
--   - HNSW vector index for O(log n) similarity search
--   - 768-dimensional embeddings (nomic-embed-text model)
--
-- Tables:
--   1. cortex_file_chunks - Stores document chunks with vector embeddings
--   2. cortex_metadata - Tracks sync status and statistics
-- ============================================

-- Enable pgvector extension for vector similarity search
CREATE EXTENSION IF NOT EXISTS vector;

-- ============================================
-- TABLE: cortex_file_chunks
-- ============================================
-- Stores chunks of documents with their vector embeddings for semantic search.
-- Each file is split into chunks (by headings, functions, or fixed size) and
-- embedded using Ollama's nomic-embed-text model.
--
-- Deduplication Strategy:
--   - file_hash: Detects when entire file changes (skip unchanged files)
--   - chunk_hash: Detects when individual chunk changes (granular updates)
--
-- Search Strategy:
--   - HNSW index provides O(log n) approximate nearest neighbor search
--   - Cosine similarity used for finding semantically similar chunks
-- ============================================

CREATE TABLE IF NOT EXISTS cortex_file_chunks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),

    -- ===================
    -- File Information
    -- ===================
    file_path TEXT NOT NULL,
        -- Relative path from project root (e.g., "src/auth/login.ts")
        -- Used to identify which file this chunk belongs to

    file_hash TEXT NOT NULL,
        -- SHA-256 hash of entire file content
        -- Used to skip re-embedding unchanged files (saves API calls)
        -- Checked before processing each file during sync

    file_type TEXT NOT NULL,
        -- File extension: 'md', 'ts', 'tsx', 'json'
        -- Determines chunking strategy:
        --   - Markdown: Split by headings (#, ##, ###)
        --   - TypeScript: Plain text chunking (AST parsing coming soon)
        --   - JSON: Whole file (usually small)

    -- ===================
    -- Chunk Information
    -- ===================
    chunk_index INTEGER NOT NULL,
        -- Position of this chunk within the file (0-based)
        -- Used to reconstruct original file order
        -- Example: File with 3 chunks has indices 0, 1, 2

    chunk_hash TEXT NOT NULL,
        -- SHA-256 hash of this chunk's content
        -- Used for granular deduplication (skip unchanged chunks)
        -- More efficient than re-embedding when only one chunk changes

    content TEXT NOT NULL,
        -- Actual text content of this chunk
        -- Max recommended: ~1024 characters (~256 tokens)
        -- Stored for displaying results and context

    token_count INTEGER NOT NULL,
        -- Estimated token count for this chunk
        -- Calculated as: length / 4 (conservative estimate)
        -- Used for tracking and debugging

    -- ===================
    -- Vector Embedding
    -- ===================
    embedding vector(768) NOT NULL,
        -- 768-dimensional vector embedding from nomic-embed-text model
        -- Generated by Ollama (100% local, no API costs)
        -- Used for semantic similarity search via cosine distance
        -- HNSW index on this column enables fast O(log n) search

    -- ===================
    -- Context Metadata
    -- ===================
    section TEXT,
        -- Contextual information about this chunk
        -- For Markdown: Heading text (e.g., "Authentication Flow")
        -- For TypeScript: Function/class name (e.g., "handleLogin")
        -- For JSON: null
        -- Helps provide better context in search results

    language TEXT,
        -- Programming language if applicable
        -- Values: 'typescript', 'json', null
        -- Used for syntax highlighting in results

    -- ===================
    -- Timestamps
    -- ===================
    created_at TIMESTAMP DEFAULT NOW() NOT NULL,
        -- When this chunk was first embedded

    updated_at TIMESTAMP DEFAULT NOW() NOT NULL
        -- When this chunk was last re-embedded
        -- Auto-updated by trigger on UPDATE
);

-- ============================================
-- INDEXES: cortex_file_chunks
-- ============================================
-- Optimized for common query patterns

-- Fast lookup by file path (for syncing, deleting)
CREATE INDEX IF NOT EXISTS idx_cortex_file_chunks_by_file_path
ON cortex_file_chunks(file_path);

-- Fast lookup by file + chunk (for unique constraint checks)
CREATE INDEX IF NOT EXISTS idx_cortex_file_chunks_by_file_and_chunk
ON cortex_file_chunks(file_path, chunk_index);

-- Fast deduplication check by file hash
CREATE INDEX IF NOT EXISTS idx_cortex_file_chunks_by_file_hash
ON cortex_file_chunks(file_hash);

-- Fast deduplication check by chunk hash
CREATE INDEX IF NOT EXISTS idx_cortex_file_chunks_by_chunk_hash
ON cortex_file_chunks(chunk_hash);

-- Filter by file type (e.g., "show me only TypeScript chunks")
CREATE INDEX IF NOT EXISTS idx_cortex_file_chunks_by_type
ON cortex_file_chunks(file_type);

-- Recent chunks (for debugging, stats)
CREATE INDEX IF NOT EXISTS idx_cortex_file_chunks_by_created_date
ON cortex_file_chunks(created_at DESC);

-- ============================================
-- VECTOR INDEX: HNSW
-- ============================================
-- Hierarchical Navigable Small World (HNSW) index for fast vector search
--
-- Parameters:
--   - m=16: Number of bi-directional links per node
--     Higher = better recall, slower insert
--     16 is good balance for 768-dim vectors
--
--   - ef_construction=64: Size of dynamic candidate list during index build
--     Higher = better index quality, slower build
--     64 is recommended for production use
--
-- Performance:
--   - Query time: O(log n) instead of O(n) for exact search
--   - Typical: <100ms for 10k chunks, <200ms for 100k chunks
--   - Trade-off: ~95-99% recall (vs 100% for exact search)
--
-- Search operator: vector_cosine_ops
--   - Uses cosine similarity: 1 - (A Â· B) / (||A|| ||B||)
--   - Range: 0 (identical) to 2 (opposite)
--   - In queries: ORDER BY embedding <=> query_vector
-- ============================================

CREATE INDEX IF NOT EXISTS idx_cortex_file_chunks_vector_search
ON cortex_file_chunks
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- ============================================
-- UNIQUE CONSTRAINT
-- ============================================
-- Ensure only one chunk per (file, position)
-- Prevents duplicate chunks when re-syncing files
-- ============================================

CREATE UNIQUE INDEX IF NOT EXISTS idx_cortex_file_chunks_unique_position
ON cortex_file_chunks(file_path, chunk_index);

-- ============================================
-- TABLE: cortex_metadata
-- ============================================
-- Tracks global statistics about embeddings and sync operations.
-- Single-row table (only one config at a time).
--
-- Purpose:
--   - Track which embedding model is being used
--   - Store aggregate statistics for dashboard
--   - Record last sync time for automation
-- ============================================

CREATE TABLE IF NOT EXISTS cortex_metadata (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),

    -- ===================
    -- Model Configuration
    -- ===================
    model_name TEXT NOT NULL DEFAULT 'nomic-embed-text',
        -- Name of the embedding model
        -- Default: nomic-embed-text (via Ollama)

    model_version TEXT NOT NULL,
        -- Version of the embedding model
        -- Example: 'v1.5'
        -- Important: Changing models requires re-embedding everything!

    embedding_dimensions INTEGER NOT NULL DEFAULT 768,
        -- Dimensionality of embeddings
        -- Must match vector(N) in cortex_file_chunks table
        -- nomic-embed-text uses 768 dimensions

    -- ===================
    -- Statistics
    -- ===================
    total_chunks INTEGER DEFAULT 0 NOT NULL,
        -- Total number of chunks in database
        -- Updated after each sync

    total_files INTEGER DEFAULT 0 NOT NULL,
        -- Total number of unique files embedded
        -- Calculated as COUNT(DISTINCT file_path)

    last_sync_at TIMESTAMP,
        -- Timestamp of most recent sync operation
        -- Used to show "last synced X hours ago"

    -- ===================
    -- Performance Metrics
    -- ===================
    avg_chunk_tokens INTEGER,
        -- Average token count per chunk
        -- Used for estimating sync time

    avg_embedding_time_ms INTEGER,
        -- Average time to generate one embedding (milliseconds)
        -- Measured during sync, used for progress estimates

    -- ===================
    -- Timestamps
    -- ===================
    created_at TIMESTAMP DEFAULT NOW() NOT NULL,
        -- When this metadata record was created

    updated_at TIMESTAMP DEFAULT NOW() NOT NULL
        -- When this metadata was last updated
        -- Auto-updated by trigger
);

-- ============================================
-- INITIAL DATA
-- ============================================
-- Insert default metadata row (only if not exists)
-- ============================================

INSERT INTO cortex_metadata (model_name, model_version, embedding_dimensions)
VALUES ('nomic-embed-text', 'v1.5', 768)
ON CONFLICT DO NOTHING;

-- ============================================
-- FUNCTION: Auto-update timestamps
-- ============================================
-- Automatically updates updated_at column when row changes
-- Used by triggers on both tables
-- ============================================

CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ language 'plpgsql';

-- ============================================
-- TRIGGERS: Auto-update updated_at
-- ============================================

-- Trigger for cortex_file_chunks table
DROP TRIGGER IF EXISTS trigger_cortex_file_chunks_updated_at ON cortex_file_chunks;
CREATE TRIGGER trigger_cortex_file_chunks_updated_at
BEFORE UPDATE ON cortex_file_chunks
FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

-- Trigger for cortex_metadata table
DROP TRIGGER IF EXISTS trigger_cortex_metadata_updated_at ON cortex_metadata;
CREATE TRIGGER trigger_cortex_metadata_updated_at
BEFORE UPDATE ON cortex_metadata
FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

-- ============================================
-- PERMISSIONS
-- ============================================
-- Grant all permissions to cortex user
-- ============================================

GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO cortex;
GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public TO cortex;
